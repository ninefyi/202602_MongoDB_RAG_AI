{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Enhancing RAG with Voyage-AI Reranking\n",
    "\n",
    "This optional lab demonstrates how to integrate Voyage-AI's reranking capabilities into your RAG pipeline. Reranking helps to improve the precision of retrieved documents, ensuring that the most relevant information is passed to the LLM, leading to higher quality responses.\n",
    "\n",
    "## Objectives\n",
    "- Understand why reranking is beneficial in RAG.\n",
    "- Implement Voyage-AI's reranking API to re-order search results.\n",
    "- Observe the impact of reranking on the context provided to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Complete Lab 1, Lab 2, and Lab 3.\n",
    "- Python environment set up with `pymongo`, `voyageai`, and `python-dotenv` installed.\n",
    "- `.env` file containing `MONGO_URI` and `VOYAGE_API_KEY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Environment Variables and Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import voyageai\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Voyage-AI Client\n",
    "voyage_api_key = os.environ.get(\"VOYAGE_API_KEY\")\n",
    "if not voyage_api_key:\n",
    "    raise ValueError(\"VOYAGE_API_KEY not found in .env file or environment variables.\")\n",
    "vo = voyageai.Client(api_key=voyage_api_key)\n",
    "\n",
    "# Initialize MongoDB Client\n",
    "mongo_uri = os.environ.get(\"MONGO_URI\")\n",
    "if not mongo_uri:\n",
    "    raise ValueError(\"MONGO_URI not found in .env file or environment variables.\")\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# Select your database and collection\n",
    "db = client['rag_db']\n",
    "collection = db['documents']\n",
    "\n",
    "print(\"Clients initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define User Query and Perform Initial Vector Search\n",
    "\n",
    "We start with a user query and perform an initial vector search, potentially retrieving more documents than strictly needed, as reranking will help us select the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What are the latest security features?\"\n",
    "print(f\"\\nUser Query: {user_query}\")\n",
    "\n",
    "print(\"Generating query embedding with Voyage-AI...\")\n",
    "try:\n",
    "    query_embedding_response = vo.embed(\n",
    "        texts=[user_query],\n",
    "        model=\"voyage-large-2\", \n",
    "        input_type=\"query\" \n",
    "    )\n",
    "    query_embedding = query_embedding_response.embeddings[0]\n",
    "    print(\"Query embedding generated.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating query embedding: {e}\")\n",
    "    exit()\n",
    "\n",
    "pipeline = [\n",
    "  {\n",
    "    '$vectorSearch': {\n",
    "      'queryVector': query_embedding,\n",
    "      'path': 'embedding',          \n",
    "      'numCandidates': 100,         # Search more candidates for reranking\n",
    "      'limit': 10,                  # Retrieve top 10 for reranking\n",
    "      'index': 'default'            \n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    '$project': {\n",
    "      'text_chunk': 1,\n",
    "      'source': 1,\n",
    "      'score': { '$meta': 'vectorSearchScore' },\n",
    "      '_id': 0 \n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "print(\"Performing initial vector search in MongoDB Atlas...\")\n",
    "initial_retrieved_documents = list(collection.aggregate(pipeline))\n",
    "\n",
    "if initial_retrieved_documents:\n",
    "    print(f\"Retrieved {len(initial_retrieved_documents)} initial documents for reranking.\")\n",
    "    for i, doc in enumerate(initial_retrieved_documents):\n",
    "        print(f\"  {i+1}. Score: {doc['score']:.4f}, Source: {doc['source']}, Text: {doc['text_chunk'][:50]}...\")\n",
    "else:\n",
    "    print(\"No initial documents found.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Rerank Documents with Voyage-AI\n",
    "\n",
    "We pass the original `user_query` and the `text_chunk`s from our initial retrieval to Voyage-AI's reranker. It will return a new set of scores indicating how relevant each document is to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_rerank = [doc['text_chunk'] for doc in initial_retrieved_documents]\n",
    "\n",
    "print(\"\\nReranking documents with Voyage-AI...\")\n",
    "try:\n",
    "    rerank_result = vo.rerank(\n",
    "        query=user_query,\n",
    "        documents=documents_to_rerank,\n",
    "        model=\"rerank-lite-1\" # Or another reranking model\n",
    "    )\n",
    "\n",
    "    # Sort the original documents based on the new relevance scores\n",
    "    reranked_documents_with_scores = sorted(\n",
    "        zip(initial_retrieved_documents, rerank_result.results),\n",
    "        key=lambda x: x[1].relevance_score, \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    print(f\"Reranked {len(reranked_documents_with_scores)} documents.\")\n",
    "    print(\"Top reranked documents:\")\n",
    "    for i, (original_doc, reranked_item) in enumerate(reranked_documents_with_scores[:5]): # Show top 5\n",
    "        print(f\"  {i+1}. Rerank Score: {reranked_item.relevance_score:.4f}, Original Score: {original_doc['score']:.4f}, Source: {original_doc['source']}, Text: {original_doc['text_chunk'][:50]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reranking documents: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Augmented Prompt with Reranked Context\n",
    "\n",
    "Now we take the top documents after reranking and use them to build the context for our LLM prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_after_rerank = 3 # Choose how many top reranked documents to send to the LLM\n",
    "final_context_chunks = [doc[0]['text_chunk'] for doc in reranked_documents_with_scores[:top_n_after_rerank]]\n",
    "context_reranked = \"\\n\".join(final_context_chunks)\n",
    "\n",
    "print(\"\\n--- Reranked Context for LLM ---\")\n",
    "print(context_reranked)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "if not context_reranked:\n",
    "    print(\"Warning: No reranked context was available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if context_reranked:\n",
    "    llm_prompt_reranked = f\"\"\"\n",
    "You are a helpful assistant. Answer the user's question based on the provided context only.\n",
    "If you cannot find the answer in the context, politely state that the information is not available.\n",
    "\n",
    "Context:\n",
    "{context_reranked}\n",
    "\n",
    "Question: {user_query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "else:\n",
    "    llm_prompt_reranked = f\"\"\"\n",
    "You are a helpful assistant. I couldn't find relevant information for the following question.\n",
    "Please state that the information is not available in the provided knowledge base.\n",
    "\n",
    "Question: {user_query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- LLM Augmented Prompt (with Reranking) ---\")\n",
    "print(llm_prompt_reranked)\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Compare this prompt's context with the one from Lab 3. The ordering and relevance\n",
    "# of the context chunks might be improved due to reranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Reranking with Voyage-AI provides an effective way to refine the search results before feeding them to an LLM, potentially leading to more accurate and relevant responses in your RAG application. This is a crucial step for optimizing performance in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close the MongoDB client connection\n",
    "client.close()\n",
    "print(\"MongoDB client connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}