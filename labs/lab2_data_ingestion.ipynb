{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Data Ingestion with Voyage-AI Embeddings into MongoDB Atlas\n",
    "\n",
    "This lab focuses on preparing your data, generating vector embeddings using Voyage-AI, and storing these embeddings along with your text chunks in a MongoDB Atlas collection. This forms the indexing part of your RAG pipeline.\n",
    "\n",
    "## Objectives\n",
    "- Define sample text data (or load from a source).\n",
    "- Use Voyage-AI to generate embeddings for text chunks.\n",
    "- Store text chunks and their embeddings in MongoDB Atlas.\n",
    "- Understand the structure of documents for vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Complete Lab 1: MongoDB Atlas Setup (ensuring `MONGODB_URI` is set in `.env`).\n",
    "- Obtain a Voyage-AI API Key and set it as `VOYAGE_API_KEY` in your `.env` file.\n",
    "- Python environment set up with `pymongo`, `voyageai`, and `python-dotenv` installed.\n",
    "  ```bash\n",
    "  pip install pymongo voyageai python-dotenv\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymongo python-dotenv voyageai tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Environment Variables and Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import voyageai\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Voyage-AI Client\n",
    "voyageai_api_key = os.environ.get(\"VOYAGEAI_API_KEY\")\n",
    "if not voyageai_api_key:\n",
    "    raise ValueError(\"VOYAGEAI_API_KEY not found in .env file or environment variables.\")\n",
    "vo = voyageai.Client(api_key=voyageai_api_key)\n",
    "\n",
    "# Initialize MongoDB Client\n",
    "mongodb_uri = os.environ.get(\"MONGODB_URI\")\n",
    "if not mongodb_uri:\n",
    "    raise ValueError(\"MONGODB_URI not found in .env file or environment variables.\")\n",
    "client = MongoClient(mongodb_uri)\n",
    "\n",
    "# Select your database and collection\n",
    "# (These will be created if they don't exist upon first insertion)\n",
    "db = client['rag_db']\n",
    "collection = db['documents']\n",
    "\n",
    "print(\"Clients initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Sample Data\n",
    "\n",
    "For this lab, we'll use a small array of text snippets. In a real-world scenario, you would typically load and chunk data from documents, articles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"The new product features include enhanced security protocols and faster processing.\",\n",
    "    \"Our customer support is available 24/7 via live chat and email.\",\n",
    "    \"This document outlines the privacy policy regarding user data collection and usage.\",\n",
    "    \"Upcoming software updates will introduce a dark mode and custom themes.\",\n",
    "    \"Please refer to the user manual for detailed installation instructions.\",\n",
    "    \"MongoDB Atlas provides a fully managed cloud database service for modern applications.\",\n",
    "    \"Vector search enables semantic similarity queries on unstructured data like text and images.\",\n",
    "    \"RAG stands for Retrieval-Augmented Generation, combining search with language model responses.\",\n",
    "    \"Voyage-AI generates high-quality embeddings optimized for retrieval and similarity tasks.\",\n",
    "    \"Cosine similarity is commonly used to measure the angle between two embedding vectors.\",\n",
    "    \"Chunking large documents into smaller pieces improves the precision of vector search results.\",\n",
    "    \"An embedding is a dense numerical representation of text that captures semantic meaning.\",\n",
    "    \"MongoDB supports flexible document schemas, making it ideal for storing heterogeneous data.\",\n",
    "    \"The vector search index must specify the number of dimensions matching the embedding model.\",\n",
    "    \"Reranking improves retrieval quality by reordering initial search results using a cross-encoder.\",\n",
    "    \"LangChain is a popular framework for building applications powered by language models.\",\n",
    "    \"A knowledge base stores curated information that an AI system can retrieve and reference.\",\n",
    "    \"Tokenization is the process of breaking text into smaller units called tokens for model input.\",\n",
    "    \"The dot product is another similarity metric used for comparing embedding vectors.\",\n",
    "    \"Prompt engineering involves crafting effective prompts to guide language model behavior.\",\n",
    "    \"Hybrid search combines keyword-based search with vector-based semantic search for better results.\",\n",
    "    \"MongoDB Atlas Search integrates full-text search and vector search in a single platform.\",\n",
    "    \"Data ingestion pipelines transform raw data into structured formats suitable for storage and retrieval.\",\n",
    "    \"The voyage-3-large model produces 1024-dimensional embeddings for high-accuracy retrieval.\",\n",
    "    \"Batch processing of embeddings reduces API calls and improves throughput during data ingestion.\",\n",
    "    \"Semantic search understands the intent behind a query, not just the exact keywords.\",\n",
    "    \"A retrieval pipeline fetches the most relevant documents from a knowledge base given a query.\",\n",
    "    \"Context window size determines how much text a language model can process in a single request.\",\n",
    "    \"Fine-tuning adjusts a pre-trained model on domain-specific data for improved performance.\",\n",
    "    \"Metadata fields like source and timestamp help filter and organize retrieved documents.\",\n",
    "    \"The pymongo library provides a Python interface for interacting with MongoDB databases.\",\n",
    "    \"Environment variables store sensitive configuration like API keys outside of source code.\",\n",
    "    \"BSON is the binary serialization format used by MongoDB to store documents internally.\",\n",
    "    \"An aggregation pipeline in MongoDB processes data through a sequence of transformation stages.\",\n",
    "    \"The $vectorSearch stage in an aggregation pipeline performs approximate nearest neighbor search.\",\n",
    "    \"Approximate nearest neighbor (ANN) algorithms trade perfect accuracy for much faster search speed.\",\n",
    "    \"Embedding models convert both queries and documents into the same vector space for comparison.\",\n",
    "    \"Atlas Vector Search uses the HNSW algorithm for efficient nearest neighbor lookups.\",\n",
    "    \"A well-designed chunk overlap strategy prevents information loss at document boundaries.\",\n",
    "    \"Temperature controls the randomness of language model outputs, lower values produce more focused text.\",\n",
    "    \"Grounding AI responses in retrieved documents reduces hallucinations and increases factual accuracy.\",\n",
    "    \"The input_type parameter in Voyage-AI distinguishes between document and query embeddings.\",\n",
    "    \"Index building in MongoDB Atlas may take several minutes depending on the volume of data.\",\n",
    "    \"Python's dotenv library loads environment variables from a .env file into the process environment.\",\n",
    "    \"Dimensionality reduction techniques like PCA can compress embeddings while preserving semantic information.\",\n",
    "    \"Cross-encoder rerankers evaluate query-document pairs jointly for more accurate relevance scoring.\",\n",
    "    \"MongoDB's flexible schema allows storing embeddings alongside text and metadata in a single document.\",\n",
    "    \"Rate limiting on embedding APIs requires implementing retry logic and batching strategies.\",\n",
    "    \"The recall metric measures the proportion of relevant documents successfully retrieved by the system.\",\n",
    "    \"Evaluation of RAG systems involves measuring both retrieval quality and generation accuracy.\",\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(sample_texts)} text chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Embeddings with Voyage-AI\n",
    "\n",
    "We'll use the `vo.embed()` method to convert our text chunks into vector embeddings. It's important to specify `input_type=\"document\"` when embedding documents for your knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating embeddings with Voyage-AI...\")\n",
    "try:\n",
    "    response = vo.embed(texts=sample_texts, model=\"voyage-3-large\", input_type=\"document\")\n",
    "    embeddings = response.embeddings\n",
    "    print(f\"Generated {len(embeddings)} embeddings. Dimension: {len(embeddings[0])}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating embeddings: {e}\")\n",
    "    # Exit or handle error appropriately\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Store Documents and Embeddings in MongoDB Atlas\n",
    "\n",
    "Now, we'll create documents for MongoDB, each containing the original text chunk, its embedding, and some optional metadata (like `source`). Then we insert them into our collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_insert = []\n",
    "for i, text in enumerate(sample_texts):\n",
    "    documents_to_insert.append({\n",
    "        \"text_chunk\": text,\n",
    "        \"embedding\": embeddings[i],\n",
    "        \"source\": f\"sample_doc_{i+1}\" # Example metadata\n",
    "    })\n",
    "\n",
    "print(f\"Preparing to insert {len(documents_to_insert)} documents...\")\n",
    "\n",
    "# Clear existing documents if you want a fresh start each time\n",
    "# collection.delete_many({})\n",
    "\n",
    "try:\n",
    "    if documents_to_insert:\n",
    "        # Check if collection is empty before inserting to avoid duplicates if run multiple times\n",
    "        if collection.count_documents({}) == 0:\n",
    "            insert_result = collection.insert_many(documents_to_insert)\n",
    "            print(f\"Successfully inserted {len(insert_result.inserted_ids)} documents into MongoDB.\")\n",
    "        else:\n",
    "            print(\"Collection is not empty. Skipping insertion to avoid duplicates. Clear the collection manually if you want to re-insert.\")\n",
    "    else:\n",
    "        print(\"No documents to insert.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting documents: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data and Plan Vector Search Index Creation\n",
    "\n",
    "You can now go to your MongoDB Atlas UI, navigate to your cluster, and browse the `rag_db.documents` collection to see the inserted data.\n",
    "\n",
    "To enable vector search, you need to create a Vector Search Index on the `embedding` field. This is typically done through the MongoDB Atlas UI.\n",
    "\n",
    "1.  In MongoDB Atlas, go to **\"DATABASE\"**.\n",
    "2.  Click **\"Search & Vector Search** tab.\n",
    "3.  Click **\"Create Search Index\"**.\n",
    "4.  Select **\"Vector Search**.\n",
    "5.  Select **\"JSON Editor\"** as the configuration method.\n",
    "6.  Enter **Index Name**: **\"vector_index\"**.\n",
    "7.  Select **`rag_db.documents`** as database and collection.\n",
    "8.  Click **Next**.\n",
    "9.  Copy and paste the following index definition:\n",
    "\n",
    "    ```json\n",
    "      {\n",
    "        \"fields\": [\n",
    "          {\n",
    "            \"type\": \"vector\",\n",
    "            \"path\": \"embedding\",\n",
    "            \"numDimensions\": 1024,\n",
    "            \"similarity\": \"cosine\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ```\n",
    "    *Remember to adjust `numDimensions` if you use a different Voyage-AI model with a different embedding size.*\n",
    "10.  Name the index `vector_index` (or a name you prefer, but remember it for Lab 3).\n",
    "11.  Click **\"Next\"**.\n",
    "12.  Click **\"Create Vector Search Index\"**.\n",
    "\n",
    "Wait for the index to build (it might take a few minutes). Once it's ready, you can proceed to Lab 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close the MongoDB client connection when done with your script/notebook\n",
    "client.close()\n",
    "print(\"MongoDB client connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
